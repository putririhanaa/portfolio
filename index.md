# Portfolio

## Data Analytics with Python 
### Data Cleansing
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1BQXcy_-jjRSzq3VP0VrukQBfotieCet0?usp=sharing)

<div style="text-align: justify">Data cleansing is an essential process for preparing raw data for machine learning (ML) and business inteligence (BI) applications. Data cleansing is the process of fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset. In this project, the data used is Telco Customer Churn Dataset from Kaggle.</div>

<div style="text-align: justify"><br>
The steps that were taken in data cleansing included: <br>
1. Missing value checking and handling, using fill method with median value.<br>
2. Categorical data encoding, using Label Encoding and Frequently Encoding.<br>
3. Anomalies and Outliers Handling. In this dataset, no anomalies or outliers were found.</div>

<center><img src="images/cleansing.png"/></center>
<center><img src="images/cleansing2.png"/></center>

### Data Manipulation with Pandas 
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1T-sRt7aKbsoKKIsJwLYKDup4Fo8Uf0Zy?usp=sharing)

<div style="text-align: justify">Data manipulation is the process of organizing data to make it more understandable. Data manipulation usually using Pandas library for join, merge, concat, and append the dataset. Before performing data visualization, data cleansing is first carried out on the dataset.</div>

<center><img src="images/manipulation.png"/></center>
<center><img src="images/manipulation1.png"/></center>

### Data Visualization
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1hFqKijt_imhRAlv6wBZwSQ6unE5S93jh?usp=sharing)

<div style="text-align: justify">Data visualization is the graphical representation of the data using visual elements like charts, graph, and maps. In this project, there will be visualized as barplot, distribution plot, boxplot, scatterplot, and pie chart using Seaborn and Matplotlib libraries. The data used is Titanic Dataset form Kaggle.</div>

<center><img src="images/vis.png"/></center>
<center><img src="images/vis1.png"/></center>

### Statistics with Python
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1jGvL9wOyajXZxuPYNbz0veeWjqxocdSA?usp=sharing)

<div style="text-align: justify">Statistics in data analytics helps make meaningful conclusion from raw and unstructured data. The conclusion that are made is used to helping businesses make future predictions on the basis of past trend. Using Diabetes dataset, statistical values (such as mean, median, mode, etc) and visualization of the dataset will be perfomed to facilitate decision-making.</div>

<center><img src="images/stat.png"/></center>
<center><img src="images/stat1.png"/></center>

### Exploratory Data Analysis
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1dsomiD3v92Lq45f4AuxWEu0e_znIVUt2?usp=sharing)

<div style="text-align: justify">Exploratory Data Analysis is the process of describing the data by means of statistical analysis and visualization techniques for deeper analytics in data analytics. Using Telco Customer Churn Dataset, Exploratory Data Analysis is well done with the following steps:</div>
1. Data understanding, including data cleansing and data manipulation.<br>
2. Statistical summary, showing statistical values from dataset.<br>
3. Univariate analysis for numerical variables by pointing out boxplot, distribution plot, and countplot.<br>
4. Bivariate analysis for numerical variables by pointing out boxplot and countplot.<br>
5. Multivariate analysis for numerical variables by pointing out correlation heatmap and category plot.</div>

<center><img src="images/eda1.png"/></center>
<center><img src="images/eda.png"/></center>

### Regression and Cluster Modeling
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/10Z6DojAHyRqnBLNAlQgQD0-56Ufv66VN?usp=sharing)

1. Regression<br>
<div style="text-align: justify">Regression is a statistical method that attempts to determine the strength and character of the relationship between dependent variable (usually denoted by Y) and a series of other variables (known as independent variables). Using House Prices - Advanced Regression Techniques Dataset, regression modeling is carried out with the following steps:</div>
1. Exploratory Data Analysis.<br>
2. Split the dataset into two parts, train and test data.<br>
3. Create a predictive model with linear regression using train data.<br>
4. Evaluate the predictive model that are made using R-Squared, Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE).<br>
  
<center><img src="images/reg.png"/></center>
  
2. Cluster using K-Means CLustering<br>
<div style="text-align: justify">K-Means Clustering is an iterative algorithm that tries to partition the dataset into Kpre-defined distinct non-overlapping subgroups (clusters) where each data point belongs to only one group. Using Mall Customers Dataset, clustering is carried out with the following steps:</div>
1. Exploratory Data Analysis.<br>
2. Determining the number of clusters with Elbow method and Silhouette method.<br>
3. Perform clustering.<br>
4. Evaluate the cluster that are made using silhouette coefficient, calinski-harabasz index, dan davies-bouldin index.</div>
  
<center><img src="images/clust.png"/></center>

---
## Machine Learning Visualizations (Data: E-Commerce Shipping Data)
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1jvbQlc_fhx_EOKYg9fNLOCRR7C8u1k64)

<div style="text-align: justify">Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy. With the help of data visualization, we can see how the data looks like and what kind of correlation is held by the attributes of data. It is the fastest way to see if the features correspond to the output. </div>

<center><img src="images/machinelearning0.png"/></center>

---
## GUI Python for Exponential Smoothing

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/putririhanaa/portfolio/blob/master/projects/exponential%20smoothing.py)
[![Open Research Poster](https://img.shields.io/badge/XLSX-Download%20Data-brightgreen)](https://github.com/putririhanaa/portfolio/blob/master/projects/runfile.xlsx)

**Exponential Smoothing:** 
<div style="text-align: justify"> Exponential Smoothing is a time series method for forecasting univariate time series data. Time series methods work on the principle that a prediction is a weighted linear sum of past observations or lags. The Exponential Smoothing time series method works by assigning exponentially decreasing weights for past observations. It is called so because the weight assigned to each demand observation is exponentially decreased. These GUI tools can be helpful for exploring your data and understanding the results of Exponential Smoothing.</div>

<div style="text-align: justify"><br>
The steps to Use the Exponential Smoothing GUI<br>
1. Click the Pilih File button<br>
2. Input file or data<br>
3. Click the Hitung button</div>

<br>
<center><img src="images/exponentialsmoothing1.png"/></center>
<br>
<center><img src="images/exponentialsmoothing.png"/></center>
<br>

---
